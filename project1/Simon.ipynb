{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transition matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_security_transition_matrix():\n",
    "    # The transition matrix is the same regardless if the game is cycled or not\n",
    "    # /!\\ index different from square number (need to do -1)\n",
    "    n_squares = 15 \n",
    "    T_m = np.zeros((n_squares, n_squares))\n",
    "    #i = index from ==> on ne commence jamais à cet index car on gagné à ce moment. La proba =1. C'est mis après \n",
    "    for i in range(n_squares-1): \n",
    "        T_m[i][i] = 1/2\n",
    "        if(i==2):\n",
    "            T_m[i][i+1] = 1/4 #if takes slow line\n",
    "            T_m[i][10] = 1/4 #if takes fast line\n",
    "        elif(i==9):\n",
    "            T_m[i][14] = 1/2            \n",
    "        else:\n",
    "            T_m[i][i+1] = 1/2\n",
    "    T_m[14][14] = 1\n",
    "    return T_m\n",
    "\n",
    "def get_normal_transition_matrix(layout, cycle:bool):\n",
    "    # The transition matrix is the same regardless tif the game is cycled or not\n",
    "    # If the player just passes through square 3 without stopping, \n",
    "    # he continues to square 4 or beyond (5, 6, etc), as if the other path does not exist\n",
    "    n_squares = 15 \n",
    "    T_m = np.zeros((n_squares, n_squares))\n",
    "    for i in range(n_squares-1): # o\n",
    "        T_m[i][i] = 1/3\n",
    "        if(i==2):\n",
    "            # #if takes slow line\n",
    "            T_m[i][i+1] = 1/6 \n",
    "            T_m[i][i+2] = 1/6\n",
    "            #if takes fast line\n",
    "            T_m[i][10] = 1/6\n",
    "            T_m[i][11] = 1/6\n",
    "\n",
    "        elif(i==8):\n",
    "            T_m[i][i+1] = 1/3\n",
    "            T_m[i][14] = 1/3\n",
    "\n",
    "        elif(i==9 or i==13):\n",
    "            if(cycle): \n",
    "                T_m[i][14] = 1/3\n",
    "                T_m[i][0] = 1/3\n",
    "            else:\n",
    "                T_m[i][14] = 2/3\n",
    "\n",
    "        else:\n",
    "            T_m[i][i+1] = 1/3\n",
    "            T_m[i][i+2] = 1/3\n",
    "    T_m[n_squares-1][n_squares-1] = 1\n",
    "\n",
    "    \n",
    "    # Il faut encore prendre les pièges et bonuses en compte \n",
    "    #il faut reparcourir Chaque élément de la T_m\n",
    "    for i in range(n_squares-1): # on ne veut pas changer le point de départ ni le point d'arrivé car il n'y a ni piège \n",
    "        for j in range(n_squares-1):\n",
    "                # une chance sur 2 de trigger le piège ou bonus\n",
    "                if(layout[j]==1 and j!=0): # type 1: go back at 1st square\n",
    "                    T_m[i][0] += T_m[i][j]/2 # il faut transférer une demi proba vers le square 1\n",
    "                    T_m[i][j] /=2 # une fois le transfert de proba fait, il faut bien l'enlever en [i][j] forcément\n",
    "                elif (layout[j]==2 and j!=0): #type 2: go back 3 squares\n",
    "                    #il y a qlq cas spéciaux\n",
    "                    if (j>=10 and j <=12): # if j ==11 12 or 13 --> go to 1,2 or 3 with proba 1/2\n",
    "                        #diff = 10\n",
    "                        T_m[i][j-10] += T_m[i][j]/2\n",
    "                        T_m[i][j] /=2 # une fois le transfert de proba fait, il faut bien l'enlever en [i][j] forcément\n",
    "                        \n",
    "                    # si trap type 2 à la case 2 ou 3, on peut pas aller moins loin que le start \n",
    "                    elif(j<3):\n",
    "                        T_m[i][0] += T_m[i][j]/2 # il faut transférer une demi proba vers le square 1\n",
    "                        T_m[i][j] /=2 # une fois le transfert de proba fait, il faut bien l'enlever en [i][j] forcément\n",
    "                        \n",
    "                    else: # cas \"commun\"\n",
    "                        T_m[i][j-3] += T_m[i][j]/2\n",
    "                        T_m[i][j] /=2 # une fois le transfert de proba fait, il faut bien l'enlever en [i][j] forcément\n",
    "                \n",
    "    return T_m\n",
    "\n",
    "def get_risky_transition_matrix(layout, cycle:bool):\n",
    "    \n",
    "    n_squares = 15\n",
    "    T_m = np.zeros((n_squares, n_squares))\n",
    "\n",
    "    for i in range(n_squares-1): # on prend le dernier square après la boucle, d'où le -1\n",
    "\n",
    "        T_m[i][i] = 1/4\n",
    "        if(i==2):\n",
    "            # #if takes slow line\n",
    "            T_m[i][i+1] = 1/8 \n",
    "            T_m[i][i+2] = 1/8\n",
    "            T_m[i][i+3] = 1/8\n",
    "            #if takes fast line\n",
    "            T_m[i][10] = 1/8\n",
    "            T_m[i][11] = 1/8\n",
    "            T_m[i][12] = 1/8\n",
    "        \n",
    "        elif(i==7):\n",
    "            T_m[i][i+1] = 1/4\n",
    "            T_m[i][i+2] = 1/4\n",
    "            T_m[i][14] = 1/4 #(du 10 au 15)\n",
    "\n",
    "        elif(i==8 or i==12):\n",
    "            T_m[i][9] = 1/4\n",
    "            if cycle :\n",
    "                T_m[i][14] = 1/4\n",
    "                T_m[i][0] = 1/4\n",
    "            else : \n",
    "                T_m[i][14] = 1/2\n",
    "        \n",
    "        elif(i==9 or i == 13):\n",
    "            if cycle :\n",
    "                T_m[i][14] = 1/4\n",
    "                T_m[i][0] = 1/4\n",
    "                T_m[i][1] = 1/4\n",
    "            else :\n",
    "                T_m[i][14] = 3/4\n",
    "        \n",
    "        else : \n",
    "            T_m[i][i+1] = 1/4\n",
    "            T_m[i][i+2] = 1/4\n",
    "            T_m[i][i+3] = 1/4\n",
    "    \n",
    "    T_m[n_squares-1][n_squares-1] = 1\n",
    "    \n",
    "    \n",
    "    # LES PIEGES :\n",
    "    for i in range(n_squares-1): # on ne veut pas changer le point de départ ni le point d'arrivé car il n'y a ni piège \n",
    "        for j in range(n_squares-1):\n",
    "            # Le trap est d'office triggered si c'en est un\n",
    "            if(layout[j]==1 and j!=0): # type 1: go back at 1st square # J'ai ajouté and j!=! pcq ca rajoutait la condition pour soit même.\n",
    "                T_m[i][0] += T_m[i][j]\n",
    "                T_m[i][j] = 0 # une fois le transfert de proba fait, il faut bien l'enlever en [i][j] forcément\n",
    "\n",
    "            elif(layout[j]== 2 and j!=0): # -3 squares\n",
    "                if (j>=10 and j <=12):\n",
    "                        #diff = 10\n",
    "                    T_m[i][j-10] += T_m[i][j]\n",
    "                    T_m[i][j] = 0 # une fois le transfert de proba fait, il faut bien l'enlever en [i][j] forcément\n",
    "                # si trap type 2 à la case 2 ou 3, on peut pas aller moins loin que le start \n",
    "                elif(j<3):\n",
    "                    T_m[i][0] += T_m[i][j] # il faut transférer une demi proba vers le square 1\n",
    "                    T_m[i][j] = 0 # une fois le transfert de proba fait, il faut bien l'enlever en [i][j] forcément\n",
    "                else: # cas \"commun\"\n",
    "                    T_m[i][j-3] += T_m[i][j]\n",
    "                    T_m[i][j] = 0 # une fois le transfert de proba fait, il faut bien l'enlever en [i][j] forcément\n",
    "            \n",
    "\n",
    "                    \n",
    "\n",
    "    return T_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if sum of probabilites equal to 1 for each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 2, 3, 1, 0, 0, 2, 2, 0, 2, 2, 4, 4, 2]\n",
      "[[0.5        0.33333333 0.16666667 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.16666667 0.33333333 0.16666667 0.33333333 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.33333333 0.08333333 0.16666667 0.16666667 0.08333333 0.\n",
      "  0.         0.         0.         0.         0.08333333 0.08333333\n",
      "  0.         0.         0.        ]\n",
      " [0.16666667 0.         0.         0.33333333 0.16666667 0.33333333\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.16666667 0.         0.         0.         0.16666667 0.33333333\n",
      "  0.33333333 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.16666667 0.33333333\n",
      "  0.33333333 0.16666667 0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.16666667 0.16666667\n",
      "  0.33333333 0.16666667 0.16666667 0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.16666667 0.16666667\n",
      "  0.         0.16666667 0.16666667 0.33333333 0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.16666667\n",
      "  0.         0.         0.16666667 0.33333333 0.         0.\n",
      "  0.         0.         0.33333333]\n",
      " [0.33333333 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.33333333 0.         0.\n",
      "  0.         0.         0.33333333]\n",
      " [0.16666667 0.16666667 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.16666667 0.16666667\n",
      "  0.33333333 0.         0.        ]\n",
      " [0.         0.16666667 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.16666667\n",
      "  0.33333333 0.33333333 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.33333333 0.33333333 0.33333333]\n",
      " [0.33333333 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.33333333 0.33333333]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         1.        ]]\n",
      "---------------------------------------\n",
      "[[0.5  0.5  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.  ]\n",
      " [0.   0.5  0.5  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.  ]\n",
      " [0.   0.   0.5  0.25 0.   0.   0.   0.   0.   0.   0.25 0.   0.   0.\n",
      "  0.  ]\n",
      " [0.   0.   0.   0.5  0.5  0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.  ]\n",
      " [0.   0.   0.   0.   0.5  0.5  0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.  ]\n",
      " [0.   0.   0.   0.   0.   0.5  0.5  0.   0.   0.   0.   0.   0.   0.\n",
      "  0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.5  0.5  0.   0.   0.   0.   0.   0.\n",
      "  0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.5  0.5  0.   0.   0.   0.   0.\n",
      "  0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.5  0.5  0.   0.   0.   0.\n",
      "  0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.5  0.   0.   0.   0.\n",
      "  0.5 ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.5  0.5  0.   0.\n",
      "  0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.5  0.5  0.\n",
      "  0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.5  0.5\n",
      "  0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.5\n",
      "  0.5 ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  1.  ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9999999999999999,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.9999999999999999,\n",
       " 1.0,\n",
       " 0.9999999999999999,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = [random.randrange(0, 5, 1) for i in range(15)]\n",
    "\n",
    "print(L)\n",
    "print(get_normal_transition_matrix(L, True))\n",
    "print(\"---------------------------------------\")\n",
    "print(get_security_transition_matrix())\n",
    "\n",
    "my_array = get_normal_transition_matrix(L, False)\n",
    "np.sum(my_array,axis=1).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Game Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimulateAGame():\n",
    "    def __init__(self, policy, layout, circle):\n",
    "        self.layout =layout\n",
    "        self.circle = circle\n",
    "        self.policy = policy\n",
    "        self.cost = 0\n",
    "\n",
    "    def get_cost_game(self):\n",
    "        \"\"\"\n",
    "        policy says which dice to take via int number: \n",
    "        - 1 : security\n",
    "        - 2 : normal \n",
    "        - 3 : risky\n",
    "        \"\"\"\n",
    "        self.cost = 0\n",
    "        return self.get_cost_from(0)\n",
    "    \n",
    "    def get_cost_from(self, index_from):\n",
    "        \"\"\" \n",
    "        \"\"\"\n",
    "        #assert(len(policy) == len(self.layout))\n",
    "        current_index = index_from \n",
    "        while(current_index != 14):\n",
    "            dice = self.policy[current_index] #{1,2,3}\n",
    "            if(dice not in [1,2,3]): raise ValueError('sorry zobi')\n",
    "            current_index = self.play(current_index, dice)\n",
    "            self.cost+=1    \n",
    "        return self.cost\n",
    "\n",
    "    def play(self, current_index, dice_type):\n",
    "        \"\"\"return resulting index\"\"\"        \n",
    "        if( dice_type == 1):  # no traps nor bonuses\n",
    "            if(current_index == 2): return np.random.choice([2,3,10], p = [0.5, 0.25, 0.25] )\n",
    "            elif (current_index == 9): return np.random.choice([9,14] )\n",
    "            else: return np.random.choice([current_index, current_index+1])\n",
    "        elif(dice_type ==2): # normal dice: 1/2 to trigger trap/bonus\n",
    "            is_triggered = np.random.choice([True,False]) #50% chance to trigger trap/bonus\n",
    "\n",
    "            if(current_index==2): next_index = np.random.choice([current_index,3,4,10,11], p = [1/3, 1/6, 1/6, 1/6, 1/6])\n",
    "            elif(current_index==8): next_index = np.random.choice([current_index,9,14])\n",
    "            elif(current_index==9 or current_index == 13):\n",
    "                if(self.circle): \n",
    "                    next_index = np.random.choice([current_index,14,0])\n",
    "                else: next_index = np.random.choice([current_index,14], p = [1/3,2/3])\n",
    "\n",
    "            # Ne faut il pas ajouté pour tous les autres cas ?\n",
    "            else : next_index = np.random.choice([current_index, current_index+1, current_index+2])\n",
    "                \n",
    "            if (is_triggered and next_index!=14): return self.activateTrapOrBonus(next_index)\n",
    "            else: return next_index\n",
    "\n",
    "        else: # type =3, i.e. risky\n",
    "            if(current_index==2):\n",
    "                next_index = np.random.choice([current_index,3,4,5, 10,11,12], p = [1/4, 1/8, 1/8, 1/8, 1/8, 1/8, 1/8])\n",
    "            elif(current_index==7):\n",
    "                next_index = np.random.choice([current_index,8,9,14])\n",
    "            elif(current_index==8):\n",
    "                if(self.circle): next_index = np.random.choice([current_index,9,14,0])\n",
    "                else: next_index = np.random.choice([current_index,9,14], p = [1/4, 1/4, 2/4])\n",
    "            elif(current_index==9):\n",
    "                if(self.circle): next_index = np.random.choice([current_index,14,0,1])\n",
    "                else: next_index = np.random.choice([current_index,14], p = [1/4, 3/4])\n",
    "            elif(current_index==12):\n",
    "                if(self.circle): next_index = np.random.choice([current_index,13,14,0])\n",
    "                else: next_index = np.random.choice([current_index,13,14], p = [1/4, 1/4, 2/4])\n",
    "            elif(current_index==13):\n",
    "                if(self.circle): next_index = np.random.choice([current_index,14,0,1])\n",
    "                else: next_index = np.random.choice([current_index,14], p = [1/4, 3/4])\n",
    "            \n",
    "            else: next_index = np.random.choice([current_index, current_index+1 , current_index+2, current_index+3])\n",
    "\n",
    "            return self.activateTrapOrBonus(next_index)\n",
    "\n",
    "    def activateTrapOrBonus(self,index):\n",
    "        if (self.layout[index] == 1): return self.activateType1Trap(index)\n",
    "        elif (self.layout[index] == 2): return self.activateType2Trap(index)\n",
    "        elif (self.layout[index] == 3): return self.activateType3Trap(index)\n",
    "        elif (self.layout[index] == 4): return self.activateBonus(index)\n",
    "        else: return index # ordinary square (0)\n",
    "\n",
    "    def activateType1Trap(self, index):\n",
    "        if (index!=14):\n",
    "            return 0\n",
    "        else : return index\n",
    "\n",
    "\n",
    "    def activateType2Trap(self, index):\n",
    "        if (index!=14):\n",
    "            if(index<3 or index == 10): \n",
    "                return 0 # or index = 10 je crois\n",
    "            elif(index == 11 or index == 12): \n",
    "                return (index-10) # Entre 11 et 12 et non entre 10 et 12\n",
    "            else: \n",
    "                return (index-3)\n",
    "        else : return index\n",
    "\n",
    "    def activateType3Trap(self, index):\n",
    "        if (index!=14):\n",
    "            self.cost += 1\n",
    "        return index\n",
    "\n",
    "    def activateBonus(self, index):\n",
    "        if (index!=14):\n",
    "            self.cost -= 1\n",
    "        return index\n",
    "    \n",
    "\n",
    "    def get_policy_history(self, policy= None):\n",
    "        if policy is None: policy = self.policy # si on ne met rien dedans, ça met la policy de base. Mais on peut voir ce que ça fait selon une politique donnée \n",
    "        history = pd.DataFrame(columns= [\"Nb_of_throws\", \"action\", \"current_index\", \"layout_info\" ])\n",
    "        current_index = 0 \n",
    "        current_cost = 0\n",
    "        while(current_index != 14):\n",
    "            dice = policy[current_index] #{1,2,3}\n",
    "            if(dice not in [1,2,3]): raise ValueError('sorry zobi')\n",
    "            # Adding information to history:\n",
    "            history.loc[len(history.index)] = [current_cost, dice, current_index, self.layout[current_index] ]\n",
    "            current_index = self.play(current_index, dice)\n",
    "            #update number of throws\n",
    "            current_cost+=1    \n",
    "            \n",
    "        return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Markov decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarkovDecision():\n",
    "\n",
    "    def __init__(self, layout:  np.ndarray, cycle:bool):\n",
    "        self.layout = layout\n",
    "        self.cycle = cycle\n",
    "        self.cost = 0\n",
    "        self.security_transition_matrix = get_security_transition_matrix()\n",
    "        self.normal_transition_matrix = get_normal_transition_matrix(layout,cycle)\n",
    "        self.get_risky_transition_matrix = get_risky_transition_matrix(layout,cycle)\n",
    "    \n",
    "    def play(self, current_index, dice_type):\n",
    "        \"\"\"return resulting index\"\"\"        \n",
    "        if( dice_type == 1):  # no traps nor bonuses\n",
    "            if(current_index == 2): return np.random.choice([2,3,10], p = [0.5, 0.25, 0.25] )\n",
    "            elif (current_index == 9): return np.random.choice([9,14] )\n",
    "            else: return np.random.choice([current_index, current_index+1])\n",
    "        elif(dice_type ==2): # normal dice: 1/2 to trigger trap/bonus\n",
    "            is_triggered = np.random.choice([True,False]) #50% chance to trigger trap/bonus\n",
    "\n",
    "            if(current_index==2): next_index = np.random.choice([current_index,3,4,10,11], p = [1/3, 1/6, 1/6, 1/6, 1/6])\n",
    "            elif(current_index==8): next_index = np.random.choice([current_index,9,14])\n",
    "            elif(current_index==9 or current_index == 13):\n",
    "                if(self.cycle): \n",
    "                    next_index = np.random.choice([current_index,14,0])\n",
    "                else: next_index = np.random.choice([current_index,14], p = [1/3,2/3])\n",
    "\n",
    "            # Ne faut il pas ajouté pour tous les autres cas ?\n",
    "            else : next_index = np.random.choice([current_index, current_index+1, current_index+2])\n",
    "                \n",
    "            if (is_triggered and next_index!=14): return self.activateTrapOrBonus(next_index)\n",
    "            else: return next_index\n",
    "\n",
    "        else: # type =3, i.e. risky\n",
    "            if(current_index==2):\n",
    "                next_index = np.random.choice([current_index,3,4,5, 10,11,12], p = [1/4, 1/8, 1/8, 1/8, 1/8, 1/8, 1/8])\n",
    "            elif(current_index==7):\n",
    "                next_index = np.random.choice([current_index,8,9,14])\n",
    "            elif(current_index==8):\n",
    "                if(self.cycle): next_index = np.random.choice([current_index,9,14,0])\n",
    "                else: next_index = np.random.choice([current_index,9,14], p = [1/4, 1/4, 2/4])\n",
    "            elif(current_index==9):\n",
    "                if(self.cycle): next_index = np.random.choice([current_index,14,0,1])\n",
    "                else: next_index = np.random.choice([current_index,14], p = [1/4, 3/4])\n",
    "            elif(current_index==12):\n",
    "                if(self.cycle): next_index = np.random.choice([current_index,13,14,0])\n",
    "                else: next_index = np.random.choice([current_index,13,14], p = [1/4, 1/4, 2/4])\n",
    "            elif(current_index==13):\n",
    "                if(self.cycle): next_index = np.random.choice([current_index,14,0,1])\n",
    "                else: next_index = np.random.choice([current_index,14], p = [1/4, 3/4])\n",
    "            \n",
    "            else: next_index = np.random.choice([current_index, current_index+1 , current_index+2, current_index+3])\n",
    "\n",
    "            return self.activateTrapOrBonus(next_index)\n",
    "\n",
    "    def activateTrapOrBonus(self,index):\n",
    "        if (self.layout[index] == 1): return self.activateType1Trap(index)\n",
    "        elif (self.layout[index] == 2): return self.activateType2Trap(index)\n",
    "        elif (self.layout[index] == 3): return self.activateType3Trap(index)\n",
    "        elif (self.layout[index] == 4): return self.activateBonus(index)\n",
    "        else: return index # ordinary square (0)\n",
    "\n",
    "    def activateType1Trap(self, index):\n",
    "        if (index!=14):\n",
    "            return 0\n",
    "        else : return index\n",
    "\n",
    "\n",
    "    def activateType2Trap(self, index):\n",
    "        if (index!=14):\n",
    "            if(index<3 or index == 10): \n",
    "                return 0 # or index = 10 je crois\n",
    "            elif(index == 11 or index == 12): \n",
    "                return (index-10) # Entre 11 et 12 et non entre 10 et 12\n",
    "            else: \n",
    "                return (index-3)\n",
    "        else : return index\n",
    "\n",
    "    def activateType3Trap(self, index):\n",
    "        if (index!=14):\n",
    "            self.cost += 1\n",
    "        return index\n",
    "\n",
    "    def activateBonus(self, index):\n",
    "        if (index!=14):\n",
    "            self.cost -= 1\n",
    "        return index\n",
    "\n",
    "    def compute_expected_cost(self, index: int, V_hat: np.array):\n",
    "        if (index in list(range(0,15))):\n",
    "            secur = np.dot(get_security_transition_matrix()[index], V_hat)\n",
    "            normal = np.dot(get_normal_transition_matrix(layout=self.layout, cycle=self.cycle)[index], V_hat)\n",
    "            risky = np.dot(get_risky_transition_matrix(layout=self.layout, cycle=self.cycle)[index], V_hat)\n",
    "\n",
    "            return(secur, normal, risky)\n",
    "            # if we want to directly know which dice to choose \n",
    "            \"\"\"\n",
    "            print(secur,' || ',  normal)\n",
    "\n",
    "            result = np.array([secur, normal])\n",
    "            min = np.min(result)\n",
    "            for i,el in enumerate(result):\n",
    "                if el == min:\n",
    "                    dice = i\n",
    "            return dice+1\"\"\"\n",
    "\n",
    "    \n",
    "    def get_policy_history(self, policy=None):\n",
    "        if policy is None: policy = self.policy # si on ne met rien dedans, ça met la policy de base. Mais on peut voir ce que ça fait selon une politique donnée \n",
    "        history = pd.DataFrame(columns= [\"Nb_of_throws\", \"action\", \"current_index\", \"layout_info\" ])\n",
    "        current_index = 0 \n",
    "        current_cost = 0\n",
    "        while(current_index != 14):\n",
    "            dice = policy[current_index] #{1,2,3}\n",
    "            if(dice not in [1,2,3]): raise ValueError('sorry zobi')\n",
    "            # Adding information to history:\n",
    "            history.loc[len(history.index)] = [current_cost, dice, current_index, self.layout[current_index] ]\n",
    "            current_index = self.play(current_index, dice)\n",
    "            #update number of throws\n",
    "            current_cost+=1    \n",
    "            \n",
    "        return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.5, 1.0, 1.5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = [0,2,3,0,0,3,2,0,2,3,0,0,3,0,0]\n",
    "secu_policy = [1,2,2,1,1,1,1,1,1,1,1,1,1,3,1]\n",
    "aGame = MarkovDecision(layout=L, cycle=True)\n",
    "aGame.compute_expected_cost(2, L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2. , 1. , 1. , 2. , 2. , 2. , 1. , 1. , 2. , 3.5, 1. , 1. , 1. ,\n",
       "       1. , 1. ])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def markovDecision(layout, cycle):\n",
    "    # déclaration/ instanciations\n",
    "    mdp = MarkovDecision(layout, cycle)\n",
    "    V_hat = np.ones(15)\n",
    "\n",
    "    index = 0\n",
    "    diff_v_hat = 100\n",
    "    count = 0\n",
    "    while(count < 100000):\n",
    "        while(index != 14):\n",
    "            # to know wich dice I choose\n",
    "            expected_cost = mdp.compute_expected_cost(index, V_hat)\n",
    "            min_expected_cost = np.min(expected_cost)\n",
    "            for i,el in enumerate(expected_cost):\n",
    "                if el == min_expected_cost:\n",
    "                    dice = i+1\n",
    "\n",
    "            # where I am landing to \n",
    "            next_index = mdp.play(index, dice)\n",
    "            # update the V_k \n",
    "            V_hat[index] += min_expected_cost\n",
    "            # update index \n",
    "            index = next_index\n",
    "            #print(index)\n",
    "        count+=1\n",
    "    print (count)\n",
    "    return V_hat\n",
    "\n",
    "markovDecision(layout=[0]*15, cycle=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Board():\n",
    "    # here we place class attribute (static members)\n",
    "    # init \n",
    "    def __init__(self, layout:  np.ndarray, cycle=False):\n",
    "        self.layout = layout\n",
    "        self.cycle = cycle\n",
    "        # self.squares = np.ones(15) # matrice 15 x 3 avec les actions et expected costs associés. \n",
    "        self.position = 0 #position actuelle du joueur\n",
    "    \n",
    "    # regular step\n",
    "    def step(self, size):\n",
    "        self.position += size\n",
    "\n",
    "    # reset (in case of circular)\n",
    "    def reset_position(self):\n",
    "        self.position = 0\n",
    "\n",
    "    def get_position(self):\n",
    "        return self.position\n",
    "    \n",
    "    def print(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dice():\n",
    "    def __init__(self, type:int):\n",
    "        self.last_toss = None\n",
    "\n",
    "        if(type == 1):\n",
    "            self.steps = np.array([0,1])\n",
    "        elif (type == 2):\n",
    "            self.steps = np.array([0,1,2])\n",
    "        elif (type== 3):\n",
    "            self.steps = np.array([0,1,2,3])\n",
    "        else: raise ValueError(' /!\\  Dice type not existing in current settings')\n",
    "        \n",
    "\n",
    "    def roll(self):\n",
    "        \"\"\" \n",
    "        draw uniformly a step from the dice\n",
    "        \"\"\"\n",
    "        self.last_toss =  int(np.random.choice(self.steps, size=1))\n",
    "        return self.last_toss\n",
    "    \n",
    "    def get_current_toss(self):\n",
    "        if(self.last_toss==None): raise ValueError(' /!\\ Dice should have been tossed at least once')\n",
    "        return self.last_toss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_proba_next_move_position(v_k, T_m):\n",
    "    # v_k = current_state proba vector\n",
    "    # return next state proba vector\n",
    "    return np.dot(v_k, T_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (16,) and (15,15) not aligned: 16 (dim 0) != 15 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/hm/tl5y8hkx5lx879s549t6c9h80000gn/T/ipykernel_57196/240400937.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mv_0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msecurity_transition_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_security_transition_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecurity_transition_matrix\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# représente la proba de la prochaine position\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (16,) and (15,15) not aligned: 16 (dim 0) != 15 (dim 0)"
     ]
    }
   ],
   "source": [
    "v_0 = np.zeros(16)\n",
    "v_0[1] = 1\n",
    "security_transition_matrix = get_security_transition_matrix()\n",
    "np.dot(v_0, security_transition_matrix) # représente la proba de la prochaine position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of Value iteration Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 4, 2, 2, 2, 3, 1, 3, 1, 3, 3, 3, 2, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "'''==================================================\n",
    "Initial set up\n",
    "=================================================='''\n",
    "\n",
    "L = [random.randrange(0, 5, 1) for i in range(15)]\n",
    "L[0] = L[-1] = 0\n",
    "\n",
    "#Hyperparameters\n",
    "SMALL_ENOUGH = 0.005\n",
    "GAMMA = 0.9 # gamma n'est pas utile    \n",
    "NOISE = 0.1 \n",
    "\n",
    "all_states= list(range(15))\n",
    "\n",
    "rewards = []\n",
    "print(L)\n",
    "for i in range(15) :\n",
    "    if(L[i] == 4) :\n",
    "        rewards.append(1)\n",
    "    else:\n",
    "        rewards.append(-1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "'''==================================================\n",
    "Initial set up\n",
    "=================================================='''\n",
    "\n",
    "#Hyperparameters\n",
    "SMALL_ENOUGH = 0.005\n",
    "GAMMA = 0.9         \n",
    "NOISE = 0.1  \n",
    "\n",
    "#Define all states\n",
    "all_states=[]\n",
    "for i in range(3):\n",
    "    for j in range(4):\n",
    "            all_states.append((i,j))\n",
    "\n",
    "#Define rewards for all states\n",
    "rewards = {}\n",
    "for i in all_states:\n",
    "    if i == (1,2):\n",
    "        rewards[i] = -1\n",
    "    elif i == (2,2):\n",
    "        rewards[i] = -1\n",
    "    elif i == (2,3):\n",
    "        rewards[i] = 1\n",
    "    else:\n",
    "        rewards[i] = 0\n",
    "\n",
    "#Dictionnary of possible actions. We have two \"end\" states (1,2 and 2,2)\n",
    "actions = {\n",
    "    (0,0):('D', 'R'), \n",
    "    (0,1):('D', 'R', 'L'),    \n",
    "    (0,2):('D', 'L', 'R'),\n",
    "    (0,3):('D', 'L'),\n",
    "    (1,0):('D', 'U', 'R'),\n",
    "    (1,1):('D', 'R', 'L', 'U'),\n",
    "    (1,3):('D', 'L', 'U'),\n",
    "    (2,0):('U', 'R'),\n",
    "    (2,1):('U', 'L', 'R'),\n",
    "    }\n",
    "\n",
    "#Define an initial policy\n",
    "policy={}\n",
    "for s in actions.keys():\n",
    "    policy[s] = np.random.choice(actions[s])\n",
    "\n",
    "#Define initial value function \n",
    "V={}\n",
    "for s in all_states:\n",
    "    if s in actions.keys():\n",
    "        V[s] = 0\n",
    "    if s ==(2,2):\n",
    "        V[s]=-1\n",
    "    if s == (1,2):\n",
    "        V[s]=-1\n",
    "    if s == (2,3):\n",
    "        V[s]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0),\n",
       " (0, 1),\n",
       " (0, 2),\n",
       " (0, 3),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (1, 2),\n",
       " (1, 3),\n",
       " (2, 0),\n",
       " (2, 1),\n",
       " (2, 2),\n",
       " (2, 3)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''==================================================\n",
    "Value Iteration\n",
    "=================================================='''\n",
    "\n",
    "iteration = 0\n",
    "while True:\n",
    "    biggest_change = 0\n",
    "    for s in all_states:            \n",
    "        if s in policy:\n",
    "            \n",
    "            old_v = V[s]\n",
    "            new_v = 0\n",
    "            \n",
    "            for a in actions[s]:\n",
    "                if a == 'U':\n",
    "                    nxt = [s[0]-1, s[1]]\n",
    "                if a == 'D':\n",
    "                    nxt = [s[0]+1, s[1]]\n",
    "                if a == 'L':\n",
    "                    nxt = [s[0], s[1]-1]\n",
    "                if a == 'R':\n",
    "                    nxt = [s[0], s[1]+1]\n",
    "\n",
    "                #Choose a new random action to do (transition probability)\n",
    "                random_1=np.random.choice([i for i in actions[s] if i != a])\n",
    "                if random_1 == 'U':\n",
    "                    act = [s[0]-1, s[1]]\n",
    "                if random_1 == 'D':\n",
    "                    act = [s[0]+1, s[1]]\n",
    "                if random_1 == 'L':\n",
    "                    act = [s[0], s[1]-1]\n",
    "                if random_1 == 'R':\n",
    "                    act = [s[0], s[1]+1]\n",
    "\n",
    "                #Calculate the value\n",
    "                nxt = tuple(nxt)\n",
    "                act = tuple(act)\n",
    "                v = rewards[s] + (GAMMA * ((1-NOISE)* V[nxt] + (NOISE * V[act]))) \n",
    "                if v > new_v: #Is this the best action so far? If so, keep it\n",
    "                    new_v = v\n",
    "                    policy[s] = a\n",
    "\n",
    "       #Save the best of all actions for the state                                 \n",
    "            V[s] = new_v\n",
    "            biggest_change = max(biggest_change, np.abs(old_v - V[s]))\n",
    "         \n",
    "   #See if the loop should stop now         \n",
    "    if biggest_change < SMALL_ENOUGH:\n",
    "        break\n",
    "    iteration += 1"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
